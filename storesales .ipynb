{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn import preprocessing\nimport tensorflow as tf\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.preprocessing import Normalizer\nimport os\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.layers import Flatten,Embedding,Dense\nfrom keras.layers.merge import Concatenate\n\nimport keras\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:26:55.088705Z","iopub.execute_input":"2022-04-03T14:26:55.089336Z","iopub.status.idle":"2022-04-03T14:26:55.096600Z","shell.execute_reply.started":"2022-04-03T14:26:55.089290Z","shell.execute_reply":"2022-04-03T14:26:55.093934Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/store-sales-time-series-forecasting/train.csv\")\n\ntest = pd.read_csv(\"../input/store-sales-time-series-forecasting/test.csv\")\n\n\ndef split_seq(a,split_length):\n    x=np.zeros((split_length,a.shape[1]))    \n    x=np.vstack([x,a])\n    sales_prev=[]\n    sales_next=[]\n\n    for i in range(split_length,x.shape[0]): \n        sales_prev.append(x[i-split_length:i])\n        sales_next.append(x[i])\n\n    \n    return np.array((sales_prev)),np.array((sales_next))\n\nsplit_len=16    \n    \npivoted_train = train.pivot(index=['date'], columns=['store_nbr', 'family'], values=['sales'])\n\ndisplay(pivoted_train)\n\nscaler3 = MinMaxScaler(feature_range=(-1, 1))\n\npivoted_train = scaler3.fit_transform(pivoted_train)\n\n\npivoted_train,pivoted_train_y=split_seq(pivoted_train,split_len)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-03T14:26:55.120346Z","iopub.execute_input":"2022-04-03T14:26:55.120544Z","iopub.status.idle":"2022-04-03T14:26:57.911700Z","shell.execute_reply.started":"2022-04-03T14:26:55.120520Z","shell.execute_reply":"2022-04-03T14:26:57.910923Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Model and Train","metadata":{}},{"cell_type":"code","source":"def network():\n    inp = layers.Input(shape=(split_len, 1782,))\n    \n    x=keras.layers.LSTM(500,activation=\"relu\",return_sequences=True)(inp)\n    x=keras.layers.BatchNormalization()(x)\n    x=keras.layers.Dropout(0.3)(x)\n    x=keras.layers.LSTM(250,activation=\"relu\")(x)\n    x=keras.layers.BatchNormalization()(x)\n    x=keras.layers.Dropout(0.3)(x)\n    out=keras.layers.Dense(1782)(x)\n    \n    model = keras.Model(inputs=inp, outputs=out)\n    return model\n\nmodel=network()\nprint(model.summary())\nmodel.compile(loss=tf.losses.MeanAbsoluteError(),\n                optimizer=tf.optimizers.Adam())\n\n\n\nmodel.fit(pivoted_train,pivoted_train_y,batch_size=256,epochs=400,validation_split=0.05)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:26:57.913433Z","iopub.execute_input":"2022-04-03T14:26:57.914021Z","iopub.status.idle":"2022-04-03T14:30:49.814618Z","shell.execute_reply.started":"2022-04-03T14:26:57.913982Z","shell.execute_reply":"2022-04-03T14:30:49.813938Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"../input/store-sales-time-series-forecasting/test.csv\")\nid=test['id']\n\ndisplay(test)\ntest=pivoted_train_y[pivoted_train_y.shape[0]-split_len:]\ntest=np.expand_dims(test,axis=0)\n\nsales=np.array([])\nfor i in range(16):\n    predictions = model.predict(test)\n    predictions=predictions.reshape(-1)\n    #sales+=predictions.reshape(-1)\n    test=np.insert(test,-1,predictions,axis=1)\n    test=np.delete(test, 0, axis=1)\n    sales=np.append(sales,predictions)\n    #test = np.array([test,predictions])\n    #predictions=np.expand_dims(predictions,axis=0)\n    #test=np.append(test[1:],predictions,axis=0)\n\n\ny_predict = pd.DataFrame(scaler3.inverse_transform(sales.reshape((16, 1782))))\nsales=y_predict.values.reshape(16*1782)\nsales = sales.clip(min=0)\ntest_results=pd.DataFrame({'id':id,'sales':sales.astype(int)})\ndisplay(test_results)\ntest_results.to_csv('results.csv' , index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T14:30:49.816061Z","iopub.execute_input":"2022-04-03T14:30:49.816322Z","iopub.status.idle":"2022-04-03T14:30:50.736899Z","shell.execute_reply.started":"2022-04-03T14:30:49.816285Z","shell.execute_reply":"2022-04-03T14:30:50.736232Z"},"trusted":true},"execution_count":34,"outputs":[]}]}